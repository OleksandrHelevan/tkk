# Лабораторна робота №2  
**Тема:** Дослідження характеристик джерел дискретних повідомлень  

**Мета:** Навчитися обчислювати інформаційні характеристики джерел та каналів дискретних повідомлень: ентропію джерела, ентропію каналу, швидкість передачі, пропускну спроможність та коефіцієнт використання каналу.

---

## 1. Частотна таблиця / гістограма

**Частотна таблиця літер українського алфавіту** (отримано на основі тексту):  

| Літера | Ймовірність |
|--------|------------|
| а      | 0.1117     |
| б      | 0.0204     |
| в      | 0.0560     |
| г      | 0.0167     |
| ґ      | 0.000014   |
| ...    | ...        |
| я      | 0.0201     |

*Гістограму частот літер можна побудувати за допомогою JFreeChart у Java.*

---

## 2. Результати обчислень

- **Ентропія джерела H(X):** 4.9415 біт/символ  
- **Ентропія завад H(Y/X):** 0.5364 біт/символ  
- **Швидкість передавання R:** 4405.12 біт/сек  
- **Пропускна спроможність C:** 5044.39 біт/сек  
- **Коефіцієнт використання η:** 0.8733  

---

## 3. Пояснення проведених обчислень

1. **Частотний аналіз:**  
   Вихідний текст оброблено для підрахунку частот літер. Отримані значення нормалізовані до ймовірностей.

2. **Ентропія джерела H(X):**  
   Розрахована за формулою:  
   \[
   H(X) = -\sum_{i=1}^{m} p(a_i) \log_2 p(a_i)
   \]

3. **Модель шумового каналу:**  
   Ймовірність помилки 5%. Ймовірність правильного символу = 0.95, помилкового символу = 0.05 / (m-1).

4. **Ентропія завад H(Y/X):**  
   Розрахована за формулою:  
   \[
   H(Y/X) = - \sum_i p(x_i) \sum_j p(y_j|x_i) \log_2 p(y_j|x_i)
   \]

5. **Швидкість передачі, пропускна спроможність та коефіцієнт використання:**  
   Використано формули:  
   \[
   R = \nu_k (H(X) - H(Y/X)), \quad
   C = \nu_k \log_2 m, \quad
   \eta = \frac{R}{C}
   \]

---

## 4. Контрольні питання

1. **Якими інформаційними характеристиками описують канали зв’язку?**  
   Ентропія джерела H(X), ентропія каналу H(Y/X), швидкість передачі R, пропускна спроможність C, коефіцієнт використання η.

2. **Що розуміють під пропускною спроможністю каналу?**  
   Максимальна швидкість, з якою інформація може передаватися каналом без втрат:  
   \[
   C = \nu_k \log_2 m
   \]

3. **Що розуміють під швидкістю передавання інформації каналом?**  
   Кількість біт реально переданої інформації за секунду:  
   \[
   R = \nu_k (H(X) - H(Y/X))
   \]

4. **Як та у якому випадку можна обчислити максимальне значення ентропії джерела повідомлень?**  
   Якщо символи рівноймовірні:  
   \[
   H_\text{max} = \log_2 m
   \]

5. **Як обчислити ентропію каналу зв’язку та завад у ньому? Наведіть приклади.**  
   Через матрицю умовних ймовірностей передачі символів:  
   \[
   H(Y/X) = - \sum_i p(x_i) \sum_j p(y_j|x_i) \log_2 p(y_j|x_i)
   \]  
   Наприклад, при ймовірності помилки 0.05: для символу «а» \(p(a|a)=0.95\), \(p(b|a)=0.0015\) і т.д.
